{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Evolutionary\n",
    "using Flux\n",
    "using Flux: onehot, onecold, logitcrossentropy, onehotbatch, crossentropy\n",
    "using MLDatasets\n",
    "using Random\n",
    "using Statistics\n",
    "using MLJBase\n",
    "using Printf\n",
    "using BSON: @load # for load weights\n",
    "using Plots\n",
    "using DelimitedFiles\n",
    "import Evolutionary.initial_population\n",
    "using Zygote\n",
    "import Evolutionary.NonDifferentiable\n",
    "import Base: copy, copyto!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TaskLocalRNG()"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Random.seed!(63456345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawdata = readdlm(\"data/test2.csv\",',',skipstart=1)';\n",
    "one = 0\n",
    "zero = 0\n",
    "for i in rawdata[20,:]\n",
    "if i == 1\n",
    "    one = one + 1\n",
    "else\n",
    "    zero = zero + 1\n",
    "end\n",
    "end\n",
    "difference = one - zero\n",
    "function newrand()\n",
    "    randCol = zeros(0)\n",
    "    push!(randCol, rand(10.0:99.0))\n",
    "    push!(randCol, rand(5.3:40.2))\n",
    "    push!(randCol, rand(1.1:15.1))\n",
    "    push!(randCol, rand(0.1:8.1))\n",
    "    push!(randCol, rand(1.1:15.1))\n",
    "    push!(randCol, rand(30.1:60.1))\n",
    "    push!(randCol, rand(0.1:0.9))\n",
    "    push!(randCol, rand(0.1:4.1))\n",
    "    push!(randCol, rand(20.1:50.1))\n",
    "    push!(randCol, rand(0.1:5.1))\n",
    "    push!(randCol, rand(0.1:7.1))\n",
    "    push!(randCol, rand(45.1:99.1))\n",
    "    push!(randCol, rand(0.1:5.1))\n",
    "    push!(randCol, rand(0.1:5.1))\n",
    "    push!(randCol, rand(0.1:7.1))\n",
    "    push!(randCol, rand(0.1:7.1))\n",
    "    push!(randCol, rand(0.1:3.1))\n",
    "    push!(randCol, rand(0.1:3.1))\n",
    "    push!(randCol, rand(0.1:5.1))\n",
    "    if rand(0:1) == 0\n",
    "        push!(randCol, 0.0)\n",
    "    else\n",
    "        push!(randCol, 1.0)\n",
    "    end\n",
    "    return randCol\n",
    "end\n",
    "for i = 1:size(rawdata,2)\n",
    "    if rawdata[20,i] == 0 && difference > 0\n",
    "        rawdata = hcat(rawdata, rawdata[:,i])\n",
    "        rawdata = hcat(rawdata, newrand())\n",
    "        difference = difference - 1\n",
    "    end\n",
    "end\n",
    "filldata = rawdata[ :, shuffle(1:end)];\n",
    "x = filldata[1:19, :]\n",
    "y = filldata[20, :];\n",
    "x_train = x[:,1:floor(Int, size(x,2)*0.7)]\n",
    "y_train = y[1:floor(Int, size(x,2)*0.7)]\n",
    "x_test = x[:,floor(Int, size(x,2)*0.7)+1:end]\n",
    "y_test = y[floor(Int, size(x,2)*0.7)+1:end];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = [ (x, onehot(l, unique(y_train))) for (x, l) in zip(eachcol(x_train), y_train)]\n",
    "test_data = [ (x, onehot(l, unique(y_test))) for (x, l) in zip(eachcol(x_test), y_test)];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "loss (generic function with 3 methods)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(xy, model) = mean( onecold(model(x)) .== onecold(y) for (x,y) in xy)\n",
    "loss(model) = (x,y)->logitcrossentropy(model(x), y)\n",
    "loss(model,x,y) = loss(model)(x, y)\n",
    "loss(xy, model) = loss(model)(hcat(map(first,xy)...), hcat(map(last,xy)...))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fitness (generic function with 1 method)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fitness(m) = loss(train_data, m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "initial_population (generic function with 6 methods)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function initial_population(method::M, individual::Chain) where {M<:Evolutionary.AbstractOptimizer}\n",
    "    θ, re = Flux.destructure(individual);\n",
    "    [re(randn(length(θ))) for i in 1:Evolutionary.population_size(method)]\n",
    "    end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "copyto! (generic function with 140 methods)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NonDifferentiable(f, x::Chain) = NonDifferentiable{Real,typeof(x)}(f, f(x), deepcopy(x),[0,])\n",
    "copy(ch::Chain) = deepcopy(ch)\n",
    "# copy weight and bias between two models\n",
    "function copyto!(layer1::Dense{T}, layer2::Dense{T}) where {T}\n",
    "    copyto!(layer1.W, layer2.W)\n",
    "    copyto!(layer1.b, layer2.b)\n",
    "    return l1\n",
    "end\n",
    "function copyto!(ch1::Chain, ch2::Chain)\n",
    "    for i in 1:length(ch1.layers)\n",
    "        copyto!(ch1.layers[i],ch2.layers[i])\n",
    "    end\n",
    "    return ch1\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = Chain(Dense(19, 2*19, sigmoid), Dense(2*19, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#methods(ES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # the iterations is performed later\n",
    "# opts = Evolutionary.Options(iterations=10,successive_f_tol= 10)\n",
    "# algo = ES(\n",
    "#     selection = :comma,\n",
    "#     mu = 10,\n",
    "#     lambda = 70,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# opts = Evolutionary.Options(iterations=1)\n",
    "\n",
    "# algo = ES(\n",
    "#     initStrategy=IsotropicStrategy(3), \n",
    "#     μ=10, \n",
    "#     ρ=3, \n",
    "#     λ=100, \n",
    "#     selection=:plus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# epochs = 500 # the number of epochs\n",
    "# # change population_size will increase training time, but may increase the accuracy\n",
    "# save_resultTest = zeros(epochs);\n",
    "# save_resultTrain = zeros(epochs);\n",
    "# # l1 = Dense(19, 2*19, sigmoid)\n",
    "# # l2 = Dense(2*19, 2)\n",
    "# model = Chain(Dense(19, 2*19, sigmoid), Dense(2*19, 2))#define the model \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in 1:10\n",
    "    \n",
    "#     # load the models saved from HW1\n",
    "#     loadpath = string(\"models/model\",i,\".bson\")\n",
    "#     @load loadpath weights\n",
    "#     Flux.loadparams!(model, weights)\n",
    "\n",
    "#     res = Evolutionary.optimize(fitness, model, algo, opts)\n",
    "#     evomodel = Evolutionary.minimizer(res)\n",
    "\n",
    "#     for j in 1:epochs\n",
    "#         res = Evolutionary.optimize(fitness, model, algo, opts)\n",
    "#         model= Evolutionary.minimizer(res)\n",
    "#         if j%(epochs/5) == 0\n",
    "#         @printf(\"Loss in expirment %d epoch: %d in test data is %f\\n\",i, j, loss(test_data,model))\n",
    "#         end\n",
    "#         save_resultTest[j] = save_resultTest[j] + accuracy(test_data, model)\n",
    "#         save_resultTrain[j] = save_resultTrain[j] + accuracy(train_data, model)\n",
    "#     end\n",
    "# end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_resultTest = save_resultTest ./ 10;\n",
    "# save_resultTrain = save_resultTrain ./ 10;\n",
    "\n",
    "# plot(log.(1:epochs), save_resultTest,label=\"Test\")\n",
    "# plot!(log.(1:epochs), save_resultTrain,label = \"Train\", title = \"Accuracy\", legend = :outertopleft)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ES(NoStrategy(), first, first, Evolutionary.var\"#42#45\"(), identity, 50, 50, 350, :comma)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opts = Evolutionary.Options(iterations=1,successive_f_tol= 2)\n",
    "algo = ES(\n",
    "    μ=50, \n",
    "    λ=3*50, \n",
    "    selection=:plus)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Chain(\n",
       "  Dense(19, 38, σ),                     \u001b[90m# 760 parameters\u001b[39m\n",
       "  Dense(38, 2),                         \u001b[90m# 78 parameters\u001b[39m\n",
       ")\u001b[90m                   # Total: 4 arrays, \u001b[39m838 parameters, 3.523 KiB."
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 600 # the number of epochs\n",
    "# change population_size will increase training time, but may increase the accuracy\n",
    "save_resultTest = zeros(epochs);\n",
    "save_resultTrain = zeros(epochs);\n",
    "# l1 = Dense(19, 2*19, sigmoid)\n",
    "# l2 = Dense(2*19, 2)\n",
    "model = Chain(Dense(19, 2*19, sigmoid), Dense(2*19, 2))#define the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "loadpath = string(\"newmodel/model\",8166,\".bson\")\n",
    "\n",
    "@load loadpath model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7365771812080537"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(test_data, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.29250720461095103"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(train_data, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "    # load the models saved from HW1\n",
    "    # loadpath = string(\"models/model\",1,\".bson\")\n",
    "    # @load loadpath weights\n",
    "    # Flux.loadparams!(model, weights)\n",
    "\n",
    "    res = Evolutionary.optimize(fitness, model, algo, opts)\n",
    "    evomodel = Evolutionary.minimizer(res)\n",
    "\n",
    "    for j in 1:epochs\n",
    "        res = Evolutionary.optimize(fitness, model, algo, opts)\n",
    "        model= Evolutionary.minimizer(res)\n",
    "        # if j%(epochs/5) == 0\n",
    "        # @printf(\"Loss in expirment %d epoch: %d in test data is %f\\n\",i, j, loss(test_data,model))\n",
    "        # end\n",
    "        save_resultTest[j] = save_resultTest[j] + accuracy(test_data, model)\n",
    "        save_resultTrain[j] = save_resultTrain[j] + accuracy(train_data, model)\n",
    "    end\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"600\" height=\"400\" viewBox=\"0 0 2400 1600\">\n<defs>\n  <clipPath id=\"clip870\">\n    <rect x=\"0\" y=\"0\" width=\"2400\" height=\"1600\"/>\n  </clipPath>\n</defs>\n<path clip-path=\"url(#clip870)\" d=\"\nM0 1600 L2400 1600 L2400 0 L0 0  Z\n  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n<defs>\n  <clipPath id=\"clip871\">\n    <rect x=\"480\" y=\"0\" width=\"1681\" height=\"1600\"/>\n  </clipPath>\n</defs>\n<path clip-path=\"url(#clip870)\" d=\"\nM707.632 1486.45 L2352.76 1486.45 L2352.76 123.472 L707.632 123.472  Z\n  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n<defs>\n  <clipPath id=\"clip872\">\n    <rect x=\"707\" y=\"123\" width=\"1646\" height=\"1364\"/>\n  </clipPath>\n</defs>\n<polyline clip-path=\"url(#clip872)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n  754.193,1486.45 754.193,123.472 \n  \"/>\n<polyline clip-path=\"url(#clip872)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n  1210.5,1486.45 1210.5,123.472 \n  \"/>\n<polyline clip-path=\"url(#clip872)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n  1666.81,1486.45 1666.81,123.472 \n  \"/>\n<polyline clip-path=\"url(#clip872)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n  2123.13,1486.45 2123.13,123.472 \n  \"/>\n<polyline clip-path=\"url(#clip870)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n  707.632,1486.45 2352.76,1486.45 \n  \"/>\n<polyline clip-path=\"url(#clip870)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n  754.193,1486.45 754.193,1467.55 \n  \"/>\n<polyline clip-path=\"url(#clip870)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n  1210.5,1486.45 1210.5,1467.55 \n  \"/>\n<polyline clip-path=\"url(#clip870)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n  1666.81,1486.45 1666.81,1467.55 \n  \"/>\n<polyline clip-path=\"url(#clip870)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n  2123.13,1486.45 2123.13,1467.55 \n  \"/>\n<path clip-path=\"url(#clip870)\" d=\"M754.193 1517.37 Q750.581 1517.37 748.753 1520.93 Q746.947 1524.47 746.947 1531.6 Q746.947 1538.71 748.753 1542.27 Q750.581 1545.82 754.193 1545.82 Q757.827 1545.82 759.632 1542.27 Q761.461 1538.71 761.461 1531.6 Q761.461 1524.47 759.632 1520.93 Q757.827 1517.37 754.193 1517.37 M754.193 1513.66 Q760.003 1513.66 763.058 1518.27 Q766.137 1522.85 766.137 1531.6 Q766.137 1540.33 763.058 1544.94 Q760.003 1549.52 754.193 1549.52 Q748.382 1549.52 745.304 1544.94 Q742.248 1540.33 742.248 1531.6 Q742.248 1522.85 745.304 1518.27 Q748.382 1513.66 754.193 1513.66 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip870)\" d=\"M1200.89 1544.91 L1208.52 1544.91 L1208.52 1518.55 L1200.21 1520.21 L1200.21 1515.95 L1208.48 1514.29 L1213.15 1514.29 L1213.15 1544.91 L1220.79 1544.91 L1220.79 1548.85 L1200.89 1548.85 L1200.89 1544.91 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip870)\" d=\"M1661.47 1544.91 L1677.79 1544.91 L1677.79 1548.85 L1655.84 1548.85 L1655.84 1544.91 Q1658.5 1542.16 1663.09 1537.53 Q1667.69 1532.88 1668.87 1531.53 Q1671.12 1529.01 1672 1527.27 Q1672.9 1525.51 1672.9 1523.82 Q1672.9 1521.07 1670.96 1519.33 Q1669.04 1517.6 1665.93 1517.6 Q1663.74 1517.6 1661.28 1518.36 Q1658.85 1519.13 1656.07 1520.68 L1656.07 1515.95 Q1658.9 1514.82 1661.35 1514.24 Q1663.81 1513.66 1665.84 1513.66 Q1671.21 1513.66 1674.41 1516.35 Q1677.6 1519.03 1677.6 1523.52 Q1677.6 1525.65 1676.79 1527.57 Q1676 1529.47 1673.9 1532.07 Q1673.32 1532.74 1670.22 1535.95 Q1667.12 1539.15 1661.47 1544.91 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip870)\" d=\"M2127.37 1530.21 Q2130.73 1530.93 2132.6 1533.2 Q2134.5 1535.47 2134.5 1538.8 Q2134.5 1543.92 2130.98 1546.72 Q2127.47 1549.52 2120.98 1549.52 Q2118.81 1549.52 2116.49 1549.08 Q2114.2 1548.66 2111.75 1547.81 L2111.75 1543.29 Q2113.69 1544.43 2116.01 1545.01 Q2118.32 1545.58 2120.85 1545.58 Q2125.24 1545.58 2127.53 1543.85 Q2129.85 1542.11 2129.85 1538.8 Q2129.85 1535.75 2127.7 1534.03 Q2125.57 1532.3 2121.75 1532.3 L2117.72 1532.3 L2117.72 1528.45 L2121.93 1528.45 Q2125.38 1528.45 2127.21 1527.09 Q2129.04 1525.7 2129.04 1523.11 Q2129.04 1520.45 2127.14 1519.03 Q2125.27 1517.6 2121.75 1517.6 Q2119.83 1517.6 2117.63 1518.01 Q2115.43 1518.43 2112.79 1519.31 L2112.79 1515.14 Q2115.45 1514.4 2117.77 1514.03 Q2120.1 1513.66 2122.16 1513.66 Q2127.49 1513.66 2130.59 1516.09 Q2133.69 1518.5 2133.69 1522.62 Q2133.69 1525.49 2132.05 1527.48 Q2130.41 1529.45 2127.37 1530.21 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><polyline clip-path=\"url(#clip872)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n  707.632,1325.2 2352.76,1325.2 \n  \"/>\n<polyline clip-path=\"url(#clip872)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n  707.632,1030.37 2352.76,1030.37 \n  \"/>\n<polyline clip-path=\"url(#clip872)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n  707.632,735.55 2352.76,735.55 \n  \"/>\n<polyline clip-path=\"url(#clip872)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n  707.632,440.727 2352.76,440.727 \n  \"/>\n<polyline clip-path=\"url(#clip872)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n  707.632,145.904 2352.76,145.904 \n  \"/>\n<polyline clip-path=\"url(#clip870)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n  707.632,1486.45 707.632,123.472 \n  \"/>\n<polyline clip-path=\"url(#clip870)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n  707.632,1325.2 721.982,1325.2 \n  \"/>\n<polyline clip-path=\"url(#clip870)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n  707.632,1030.37 721.982,1030.37 \n  \"/>\n<polyline clip-path=\"url(#clip870)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n  707.632,735.55 721.982,735.55 \n  \"/>\n<polyline clip-path=\"url(#clip870)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n  707.632,440.727 721.982,440.727 \n  \"/>\n<polyline clip-path=\"url(#clip870)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n  707.632,145.904 721.982,145.904 \n  \"/>\n<path clip-path=\"url(#clip870)\" d=\"M584.295 1310.99 Q580.684 1310.99 578.855 1314.56 Q577.05 1318.1 577.05 1325.23 Q577.05 1332.34 578.855 1335.9 Q580.684 1339.44 584.295 1339.44 Q587.929 1339.44 589.735 1335.9 Q591.563 1332.34 591.563 1325.23 Q591.563 1318.1 589.735 1314.56 Q587.929 1310.99 584.295 1310.99 M584.295 1307.29 Q590.105 1307.29 593.161 1311.9 Q596.239 1316.48 596.239 1325.23 Q596.239 1333.96 593.161 1338.56 Q590.105 1343.15 584.295 1343.15 Q578.485 1343.15 575.406 1338.56 Q572.351 1333.96 572.351 1325.23 Q572.351 1316.48 575.406 1311.9 Q578.485 1307.29 584.295 1307.29 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip870)\" d=\"M604.457 1336.6 L609.341 1336.6 L609.341 1342.48 L604.457 1342.48 L604.457 1336.6 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip870)\" d=\"M632.373 1311.99 L620.568 1330.44 L632.373 1330.44 L632.373 1311.99 M631.147 1307.92 L637.026 1307.92 L637.026 1330.44 L641.957 1330.44 L641.957 1334.33 L637.026 1334.33 L637.026 1342.48 L632.373 1342.48 L632.373 1334.33 L616.772 1334.33 L616.772 1329.81 L631.147 1307.92 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip870)\" d=\"M659.688 1310.99 Q656.077 1310.99 654.248 1314.56 Q652.443 1318.1 652.443 1325.23 Q652.443 1332.34 654.248 1335.9 Q656.077 1339.44 659.688 1339.44 Q663.322 1339.44 665.128 1335.9 Q666.957 1332.34 666.957 1325.23 Q666.957 1318.1 665.128 1314.56 Q663.322 1310.99 659.688 1310.99 M659.688 1307.29 Q665.498 1307.29 668.554 1311.9 Q671.632 1316.48 671.632 1325.23 Q671.632 1333.96 668.554 1338.56 Q665.498 1343.15 659.688 1343.15 Q653.878 1343.15 650.799 1338.56 Q647.744 1333.96 647.744 1325.23 Q647.744 1316.48 650.799 1311.9 Q653.878 1307.29 659.688 1307.29 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip870)\" d=\"M585.29 1016.17 Q581.679 1016.17 579.851 1019.74 Q578.045 1023.28 578.045 1030.41 Q578.045 1037.51 579.851 1041.08 Q581.679 1044.62 585.29 1044.62 Q588.925 1044.62 590.73 1041.08 Q592.559 1037.51 592.559 1030.41 Q592.559 1023.28 590.73 1019.74 Q588.925 1016.17 585.29 1016.17 M585.29 1012.47 Q591.1 1012.47 594.156 1017.07 Q597.235 1021.66 597.235 1030.41 Q597.235 1039.13 594.156 1043.74 Q591.1 1048.32 585.29 1048.32 Q579.48 1048.32 576.401 1043.74 Q573.346 1039.13 573.346 1030.41 Q573.346 1021.66 576.401 1017.07 Q579.48 1012.47 585.29 1012.47 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip870)\" d=\"M605.452 1041.77 L610.336 1041.77 L610.336 1047.65 L605.452 1047.65 L605.452 1041.77 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip870)\" d=\"M633.369 1017.17 L621.563 1035.62 L633.369 1035.62 L633.369 1017.17 M632.142 1013.09 L638.022 1013.09 L638.022 1035.62 L642.952 1035.62 L642.952 1039.5 L638.022 1039.5 L638.022 1047.65 L633.369 1047.65 L633.369 1039.5 L617.767 1039.5 L617.767 1034.99 L632.142 1013.09 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip870)\" d=\"M650.73 1013.09 L669.086 1013.09 L669.086 1017.03 L655.012 1017.03 L655.012 1025.5 Q656.031 1025.15 657.049 1024.99 Q658.068 1024.81 659.086 1024.81 Q664.873 1024.81 668.253 1027.98 Q671.632 1031.15 671.632 1036.56 Q671.632 1042.14 668.16 1045.24 Q664.688 1048.32 658.369 1048.32 Q656.193 1048.32 653.924 1047.95 Q651.679 1047.58 649.271 1046.84 L649.271 1042.14 Q651.355 1043.28 653.577 1043.83 Q655.799 1044.39 658.276 1044.39 Q662.281 1044.39 664.619 1042.28 Q666.957 1040.18 666.957 1036.56 Q666.957 1032.95 664.619 1030.85 Q662.281 1028.74 658.276 1028.74 Q656.401 1028.74 654.526 1029.16 Q652.674 1029.57 650.73 1030.45 L650.73 1013.09 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip870)\" d=\"M584.295 721.348 Q580.684 721.348 578.855 724.913 Q577.05 728.455 577.05 735.584 Q577.05 742.691 578.855 746.255 Q580.684 749.797 584.295 749.797 Q587.929 749.797 589.735 746.255 Q591.563 742.691 591.563 735.584 Q591.563 728.455 589.735 724.913 Q587.929 721.348 584.295 721.348 M584.295 717.645 Q590.105 717.645 593.161 722.251 Q596.239 726.834 596.239 735.584 Q596.239 744.311 593.161 748.917 Q590.105 753.501 584.295 753.501 Q578.485 753.501 575.406 748.917 Q572.351 744.311 572.351 735.584 Q572.351 726.834 575.406 722.251 Q578.485 717.645 584.295 717.645 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip870)\" d=\"M604.457 746.95 L609.341 746.95 L609.341 752.83 L604.457 752.83 L604.457 746.95 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip870)\" d=\"M619.573 718.27 L637.929 718.27 L637.929 722.205 L623.855 722.205 L623.855 730.677 Q624.873 730.33 625.892 730.168 Q626.91 729.982 627.929 729.982 Q633.716 729.982 637.096 733.154 Q640.475 736.325 640.475 741.742 Q640.475 747.32 637.003 750.422 Q633.531 753.501 627.211 753.501 Q625.035 753.501 622.767 753.13 Q620.522 752.76 618.114 752.019 L618.114 747.32 Q620.198 748.455 622.42 749.01 Q624.642 749.566 627.119 749.566 Q631.123 749.566 633.461 747.459 Q635.799 745.353 635.799 741.742 Q635.799 738.131 633.461 736.024 Q631.123 733.918 627.119 733.918 Q625.244 733.918 623.369 734.334 Q621.517 734.751 619.573 735.631 L619.573 718.27 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip870)\" d=\"M659.688 721.348 Q656.077 721.348 654.248 724.913 Q652.443 728.455 652.443 735.584 Q652.443 742.691 654.248 746.255 Q656.077 749.797 659.688 749.797 Q663.322 749.797 665.128 746.255 Q666.957 742.691 666.957 735.584 Q666.957 728.455 665.128 724.913 Q663.322 721.348 659.688 721.348 M659.688 717.645 Q665.498 717.645 668.554 722.251 Q671.632 726.834 671.632 735.584 Q671.632 744.311 668.554 748.917 Q665.498 753.501 659.688 753.501 Q653.878 753.501 650.799 748.917 Q647.744 744.311 647.744 735.584 Q647.744 726.834 650.799 722.251 Q653.878 717.645 659.688 717.645 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip870)\" d=\"M585.29 426.525 Q581.679 426.525 579.851 430.09 Q578.045 433.632 578.045 440.761 Q578.045 447.868 579.851 451.433 Q581.679 454.974 585.29 454.974 Q588.925 454.974 590.73 451.433 Q592.559 447.868 592.559 440.761 Q592.559 433.632 590.73 430.09 Q588.925 426.525 585.29 426.525 M585.29 422.822 Q591.1 422.822 594.156 427.428 Q597.235 432.011 597.235 440.761 Q597.235 449.488 594.156 454.095 Q591.1 458.678 585.29 458.678 Q579.48 458.678 576.401 454.095 Q573.346 449.488 573.346 440.761 Q573.346 432.011 576.401 427.428 Q579.48 422.822 585.29 422.822 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip870)\" d=\"M605.452 452.127 L610.336 452.127 L610.336 458.007 L605.452 458.007 L605.452 452.127 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip870)\" d=\"M620.568 423.447 L638.924 423.447 L638.924 427.382 L624.85 427.382 L624.85 435.854 Q625.869 435.507 626.887 435.345 Q627.906 435.16 628.924 435.16 Q634.711 435.16 638.091 438.331 Q641.471 441.502 641.471 446.919 Q641.471 452.497 637.998 455.599 Q634.526 458.678 628.207 458.678 Q626.031 458.678 623.762 458.308 Q621.517 457.937 619.11 457.197 L619.11 452.497 Q621.193 453.632 623.415 454.187 Q625.637 454.743 628.114 454.743 Q632.119 454.743 634.457 452.636 Q636.795 450.53 636.795 446.919 Q636.795 443.308 634.457 441.201 Q632.119 439.095 628.114 439.095 Q626.239 439.095 624.364 439.511 Q622.512 439.928 620.568 440.808 L620.568 423.447 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip870)\" d=\"M650.73 423.447 L669.086 423.447 L669.086 427.382 L655.012 427.382 L655.012 435.854 Q656.031 435.507 657.049 435.345 Q658.068 435.16 659.086 435.16 Q664.873 435.16 668.253 438.331 Q671.632 441.502 671.632 446.919 Q671.632 452.497 668.16 455.599 Q664.688 458.678 658.369 458.678 Q656.193 458.678 653.924 458.308 Q651.679 457.937 649.271 457.197 L649.271 452.497 Q651.355 453.632 653.577 454.187 Q655.799 454.743 658.276 454.743 Q662.281 454.743 664.619 452.636 Q666.957 450.53 666.957 446.919 Q666.957 443.308 664.619 441.201 Q662.281 439.095 658.276 439.095 Q656.401 439.095 654.526 439.511 Q652.674 439.928 650.73 440.808 L650.73 423.447 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip870)\" d=\"M584.295 131.703 Q580.684 131.703 578.855 135.267 Q577.05 138.809 577.05 145.939 Q577.05 153.045 578.855 156.61 Q580.684 160.151 584.295 160.151 Q587.929 160.151 589.735 156.61 Q591.563 153.045 591.563 145.939 Q591.563 138.809 589.735 135.267 Q587.929 131.703 584.295 131.703 M584.295 127.999 Q590.105 127.999 593.161 132.605 Q596.239 137.189 596.239 145.939 Q596.239 154.665 593.161 159.272 Q590.105 163.855 584.295 163.855 Q578.485 163.855 575.406 159.272 Q572.351 154.665 572.351 145.939 Q572.351 137.189 575.406 132.605 Q578.485 127.999 584.295 127.999 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip870)\" d=\"M604.457 157.304 L609.341 157.304 L609.341 163.184 L604.457 163.184 L604.457 157.304 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip870)\" d=\"M630.105 144.04 Q626.957 144.04 625.105 146.193 Q623.276 148.346 623.276 152.096 Q623.276 155.823 625.105 157.999 Q626.957 160.151 630.105 160.151 Q633.253 160.151 635.082 157.999 Q636.934 155.823 636.934 152.096 Q636.934 148.346 635.082 146.193 Q633.253 144.04 630.105 144.04 M639.387 129.388 L639.387 133.647 Q637.628 132.814 635.822 132.374 Q634.04 131.934 632.281 131.934 Q627.651 131.934 625.198 135.059 Q622.767 138.184 622.42 144.503 Q623.785 142.49 625.846 141.425 Q627.906 140.337 630.383 140.337 Q635.591 140.337 638.6 143.508 Q641.633 146.656 641.633 152.096 Q641.633 157.42 638.484 160.638 Q635.336 163.855 630.105 163.855 Q624.11 163.855 620.938 159.272 Q617.767 154.665 617.767 145.939 Q617.767 137.744 621.656 132.883 Q625.545 127.999 632.096 127.999 Q633.855 127.999 635.637 128.346 Q637.443 128.693 639.387 129.388 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip870)\" d=\"M659.688 131.703 Q656.077 131.703 654.248 135.267 Q652.443 138.809 652.443 145.939 Q652.443 153.045 654.248 156.61 Q656.077 160.151 659.688 160.151 Q663.322 160.151 665.128 156.61 Q666.957 153.045 666.957 145.939 Q666.957 138.809 665.128 135.267 Q663.322 131.703 659.688 131.703 M659.688 127.999 Q665.498 127.999 668.554 132.605 Q671.632 137.189 671.632 145.939 Q671.632 154.665 668.554 159.272 Q665.498 163.855 659.688 163.855 Q653.878 163.855 650.799 159.272 Q647.744 154.665 647.744 145.939 Q647.744 137.189 650.799 132.605 Q653.878 127.999 659.688 127.999 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip870)\" d=\"M1370.08 20.1573 L1358.98 50.2555 L1381.22 50.2555 L1370.08 20.1573 M1365.46 12.096 L1374.74 12.096 L1397.79 72.576 L1389.28 72.576 L1383.77 57.061 L1356.51 57.061 L1351 72.576 L1342.37 72.576 L1365.46 12.096 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip870)\" d=\"M1437.49 28.9478 L1437.49 35.9153 Q1434.33 34.1734 1431.13 33.3227 Q1427.97 32.4315 1424.73 32.4315 Q1417.48 32.4315 1413.47 37.0496 Q1409.46 41.6271 1409.46 49.9314 Q1409.46 58.2358 1413.47 62.8538 Q1417.48 67.4314 1424.73 67.4314 Q1427.97 67.4314 1431.13 66.5807 Q1434.33 65.6895 1437.49 63.9476 L1437.49 70.8341 Q1434.37 72.2924 1431.01 73.0216 Q1427.69 73.7508 1423.92 73.7508 Q1413.67 73.7508 1407.63 67.3098 Q1401.6 60.8689 1401.6 49.9314 Q1401.6 38.832 1407.67 32.472 Q1413.79 26.1121 1424.4 26.1121 Q1427.85 26.1121 1431.13 26.8413 Q1434.41 27.5299 1437.49 28.9478 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip870)\" d=\"M1483.1 28.9478 L1483.1 35.9153 Q1479.94 34.1734 1476.74 33.3227 Q1473.58 32.4315 1470.34 32.4315 Q1463.09 32.4315 1459.08 37.0496 Q1455.07 41.6271 1455.07 49.9314 Q1455.07 58.2358 1459.08 62.8538 Q1463.09 67.4314 1470.34 67.4314 Q1473.58 67.4314 1476.74 66.5807 Q1479.94 65.6895 1483.1 63.9476 L1483.1 70.8341 Q1479.98 72.2924 1476.62 73.0216 Q1473.3 73.7508 1469.53 73.7508 Q1459.28 73.7508 1453.25 67.3098 Q1447.21 60.8689 1447.21 49.9314 Q1447.21 38.832 1453.29 32.472 Q1459.4 26.1121 1470.02 26.1121 Q1473.46 26.1121 1476.74 26.8413 Q1480.02 27.5299 1483.1 28.9478 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip870)\" d=\"M1495.3 54.671 L1495.3 27.2059 L1502.75 27.2059 L1502.75 54.3874 Q1502.75 60.8284 1505.26 64.0691 Q1507.77 67.2693 1512.8 67.2693 Q1518.83 67.2693 1522.32 63.421 Q1525.84 59.5726 1525.84 52.9291 L1525.84 27.2059 L1533.29 27.2059 L1533.29 72.576 L1525.84 72.576 L1525.84 65.6084 Q1523.13 69.7404 1519.52 71.7658 Q1515.96 73.7508 1511.22 73.7508 Q1503.4 73.7508 1499.35 68.8897 Q1495.3 64.0286 1495.3 54.671 M1514.05 26.1121 L1514.05 26.1121 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip870)\" d=\"M1574.94 34.1734 Q1573.68 33.4443 1572.18 33.1202 Q1570.72 32.7556 1568.94 32.7556 Q1562.62 32.7556 1559.22 36.8875 Q1555.86 40.9789 1555.86 48.6757 L1555.86 72.576 L1548.36 72.576 L1548.36 27.2059 L1555.86 27.2059 L1555.86 34.2544 Q1558.21 30.1225 1561.97 28.1376 Q1565.74 26.1121 1571.13 26.1121 Q1571.9 26.1121 1572.83 26.2337 Q1573.76 26.3147 1574.9 26.5172 L1574.94 34.1734 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip870)\" d=\"M1603.37 49.7694 Q1594.34 49.7694 1590.86 51.8354 Q1587.37 53.9013 1587.37 58.8839 Q1587.37 62.8538 1589.97 65.2034 Q1592.6 67.5124 1597.09 67.5124 Q1603.29 67.5124 1607.02 63.1374 Q1610.79 58.7219 1610.79 51.4303 L1610.79 49.7694 L1603.37 49.7694 M1618.24 46.6907 L1618.24 72.576 L1610.79 72.576 L1610.79 65.6895 Q1608.23 69.8214 1604.43 71.8063 Q1600.62 73.7508 1595.11 73.7508 Q1588.14 73.7508 1584.01 69.8619 Q1579.92 65.9325 1579.92 59.3701 Q1579.92 51.7138 1585.02 47.825 Q1590.17 43.9361 1600.34 43.9361 L1610.79 43.9361 L1610.79 43.2069 Q1610.79 38.0623 1607.38 35.2672 Q1604.02 32.4315 1597.91 32.4315 Q1594.02 32.4315 1590.33 33.3632 Q1586.64 34.295 1583.24 36.1584 L1583.24 29.2718 Q1587.33 27.692 1591.18 26.9223 Q1595.03 26.1121 1598.67 26.1121 Q1608.52 26.1121 1613.38 31.2163 Q1618.24 36.3204 1618.24 46.6907 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip870)\" d=\"M1666.24 28.9478 L1666.24 35.9153 Q1663.08 34.1734 1659.88 33.3227 Q1656.72 32.4315 1653.48 32.4315 Q1646.23 32.4315 1642.22 37.0496 Q1638.21 41.6271 1638.21 49.9314 Q1638.21 58.2358 1642.22 62.8538 Q1646.23 67.4314 1653.48 67.4314 Q1656.72 67.4314 1659.88 66.5807 Q1663.08 65.6895 1666.24 63.9476 L1666.24 70.8341 Q1663.12 72.2924 1659.76 73.0216 Q1656.44 73.7508 1652.67 73.7508 Q1642.42 73.7508 1636.39 67.3098 Q1630.35 60.8689 1630.35 49.9314 Q1630.35 38.832 1636.43 32.472 Q1642.55 26.1121 1653.16 26.1121 Q1656.6 26.1121 1659.88 26.8413 Q1663.17 27.5299 1666.24 28.9478 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip870)\" d=\"M1698.08 76.7889 Q1694.92 84.8907 1691.93 87.3618 Q1688.93 89.8329 1683.91 89.8329 L1677.95 89.8329 L1677.95 83.5945 L1682.33 83.5945 Q1685.4 83.5945 1687.11 82.1361 Q1688.81 80.6778 1690.87 75.2496 L1692.21 71.8468 L1673.86 27.2059 L1681.76 27.2059 L1695.94 62.6918 L1710.12 27.2059 L1718.01 27.2059 L1698.08 76.7889 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><polyline clip-path=\"url(#clip872)\" style=\"stroke:#009af9; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n  754.193,1329.15 1070.48,804.803 1255.5,616.829 1386.77,834.483 1488.6,804.803 1571.79,854.27 1642.13,1002.67 1703.06,913.63 1756.81,616.829 1804.89,676.189 \n  1848.38,379.388 1888.08,1071.92 1924.61,765.23 1958.42,1279.69 1989.91,913.63 2019.35,1012.56 2047.02,1032.35 2073.1,577.255 2097.77,1002.67 2121.18,616.829 \n  2143.44,695.976 2164.67,1447.87 2184.95,953.204 2204.37,715.763 2223,636.616 2240.9,527.788 2258.12,864.163 2274.71,814.697 2290.73,883.95 2306.2,864.163 \n  \n  \"/>\n<polyline clip-path=\"url(#clip872)\" style=\"stroke:#e26f46; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n  754.193,162.047 1070.48,727.053 1255.5,850.25 1386.77,790.776 1488.6,812.017 1571.79,586.864 1642.13,506.148 1703.06,480.659 1756.81,671.827 1804.89,778.031 \n  1848.38,952.206 1888.08,429.681 1924.61,608.104 1958.42,162.047 1989.91,680.323 2019.35,399.944 2047.02,361.711 2073.1,833.257 2097.77,467.915 2121.18,799.272 \n  2143.44,731.301 2164.67,302.236 2184.95,450.922 2204.37,654.834 2223,837.506 2240.9,637.842 2258.12,667.579 2274.71,340.47 2290.73,705.812 2306.2,586.864 \n  \n  \"/>\n<path clip-path=\"url(#clip870)\" d=\"\nM114.058 324.425 L463.918 324.425 L463.918 168.905 L114.058 168.905  Z\n  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n<polyline clip-path=\"url(#clip870)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n  114.058,324.425 463.918,324.425 463.918,168.905 114.058,168.905 114.058,324.425 \n  \"/>\n<polyline clip-path=\"url(#clip870)\" style=\"stroke:#009af9; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n  138.058,220.745 282.058,220.745 \n  \"/>\n<path clip-path=\"url(#clip870)\" d=\"M306.058 203.465 L335.294 203.465 L335.294 207.4 L323.025 207.4 L323.025 238.025 L318.326 238.025 L318.326 207.4 L306.058 207.4 L306.058 203.465 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip870)\" d=\"M353.743 223.997 L353.743 226.08 L334.16 226.08 Q334.437 230.478 336.799 232.793 Q339.183 235.085 343.419 235.085 Q345.873 235.085 348.164 234.483 Q350.479 233.881 352.748 232.677 L352.748 236.705 Q350.456 237.677 348.048 238.187 Q345.641 238.696 343.164 238.696 Q336.961 238.696 333.326 235.085 Q329.715 231.474 329.715 225.316 Q329.715 218.951 333.141 215.224 Q336.59 211.474 342.423 211.474 Q347.655 211.474 350.687 214.853 Q353.743 218.21 353.743 223.997 M349.484 222.747 Q349.437 219.252 347.516 217.168 Q345.618 215.085 342.47 215.085 Q338.905 215.085 336.752 217.099 Q334.623 219.113 334.299 222.77 L349.484 222.747 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip870)\" d=\"M377.261 212.863 L377.261 216.891 Q375.456 215.965 373.511 215.502 Q371.567 215.039 369.484 215.039 Q366.312 215.039 364.715 216.011 Q363.141 216.983 363.141 218.928 Q363.141 220.409 364.275 221.265 Q365.409 222.099 368.835 222.863 L370.294 223.187 Q374.831 224.159 376.729 225.941 Q378.65 227.701 378.65 230.872 Q378.65 234.483 375.78 236.589 Q372.933 238.696 367.933 238.696 Q365.849 238.696 363.581 238.279 Q361.335 237.886 358.835 237.076 L358.835 232.677 Q361.197 233.904 363.488 234.529 Q365.78 235.131 368.025 235.131 Q371.034 235.131 372.655 234.113 Q374.275 233.071 374.275 231.196 Q374.275 229.46 373.095 228.534 Q371.937 227.608 367.979 226.752 L366.497 226.404 Q362.539 225.571 360.78 223.858 Q359.021 222.122 359.021 219.113 Q359.021 215.455 361.613 213.465 Q364.206 211.474 368.974 211.474 Q371.335 211.474 373.419 211.821 Q375.502 212.168 377.261 212.863 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip870)\" d=\"M389.645 204.738 L389.645 212.099 L398.419 212.099 L398.419 215.409 L389.645 215.409 L389.645 229.483 Q389.645 232.654 390.502 233.557 Q391.382 234.46 394.044 234.46 L398.419 234.46 L398.419 238.025 L394.044 238.025 Q389.113 238.025 387.238 236.196 Q385.363 234.344 385.363 229.483 L385.363 215.409 L382.238 215.409 L382.238 212.099 L385.363 212.099 L385.363 204.738 L389.645 204.738 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><polyline clip-path=\"url(#clip870)\" style=\"stroke:#e26f46; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n  138.058,272.585 282.058,272.585 \n  \"/>\n<path clip-path=\"url(#clip870)\" d=\"M306.058 255.305 L335.294 255.305 L335.294 259.24 L323.025 259.24 L323.025 289.865 L318.326 289.865 L318.326 259.24 L306.058 259.24 L306.058 255.305 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip870)\" d=\"M347.678 267.92 Q346.96 267.504 346.104 267.318 Q345.271 267.11 344.252 267.11 Q340.641 267.11 338.697 269.471 Q336.775 271.809 336.775 276.207 L336.775 289.865 L332.493 289.865 L332.493 263.939 L336.775 263.939 L336.775 267.967 Q338.118 265.606 340.271 264.471 Q342.423 263.314 345.502 263.314 Q345.942 263.314 346.474 263.383 Q347.007 263.43 347.655 263.545 L347.678 267.92 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip870)\" d=\"M363.928 276.832 Q358.766 276.832 356.775 278.013 Q354.785 279.193 354.785 282.041 Q354.785 284.309 356.266 285.652 Q357.771 286.971 360.34 286.971 Q363.882 286.971 366.011 284.471 Q368.164 281.948 368.164 277.781 L368.164 276.832 L363.928 276.832 M372.423 275.073 L372.423 289.865 L368.164 289.865 L368.164 285.929 Q366.706 288.291 364.53 289.425 Q362.354 290.536 359.206 290.536 Q355.224 290.536 352.863 288.314 Q350.525 286.068 350.525 282.318 Q350.525 277.943 353.442 275.721 Q356.382 273.499 362.192 273.499 L368.164 273.499 L368.164 273.082 Q368.164 270.143 366.22 268.545 Q364.298 266.925 360.803 266.925 Q358.581 266.925 356.474 267.457 Q354.368 267.99 352.423 269.055 L352.423 265.119 Q354.761 264.217 356.96 263.777 Q359.16 263.314 361.243 263.314 Q366.868 263.314 369.646 266.231 Q372.423 269.147 372.423 275.073 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip870)\" d=\"M381.196 263.939 L385.456 263.939 L385.456 289.865 L381.196 289.865 L381.196 263.939 M381.196 253.846 L385.456 253.846 L385.456 259.24 L381.196 259.24 L381.196 253.846 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip870)\" d=\"M415.918 274.217 L415.918 289.865 L411.659 289.865 L411.659 274.355 Q411.659 270.675 410.224 268.846 Q408.789 267.018 405.919 267.018 Q402.469 267.018 400.479 269.217 Q398.488 271.416 398.488 275.212 L398.488 289.865 L394.206 289.865 L394.206 263.939 L398.488 263.939 L398.488 267.967 Q400.016 265.629 402.076 264.471 Q404.159 263.314 406.868 263.314 Q411.335 263.314 413.627 266.092 Q415.918 268.846 415.918 274.217 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /></svg>\n"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_resultTest = save_resultTest ./ 1;\n",
    "save_resultTrain = save_resultTrain ./ 1;\n",
    "\n",
    "plot(log.(1:epochs), save_resultTest,label=\"Test\")\n",
    "plot!(log.(1:epochs), save_resultTrain,label = \"Train\", title = \"Accuracy\", legend = :outertopleft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConfusionMatrix for the training data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Warning: The classes are un-ordered,\n",
      "│ using: negative='0' and positive='1'.\n",
      "│ To suppress this warning, consider coercing to OrderedFactor.\n",
      "└ @ MLJBase C:\\Users\\xkzmx\\.julia\\packages\\MLJBase\\pCiRR\\src\\measures\\confusion_matrix.jl:112\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "              ┌───────────────────────────┐\n",
       "              │       Ground Truth        │\n",
       "┌─────────────┼─────────────┬─────────────┤\n",
       "│  Predicted  │      0      │      1      │\n",
       "├─────────────┼─────────────┼─────────────┤\n",
       "│      0      │     514     │     275     │\n",
       "├─────────────┼─────────────┼─────────────┤\n",
       "│      1      │     175     │     424     │\n",
       "└─────────────┴─────────────┴─────────────┘\n"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simplified_x_train_result = []\n",
    "for i  = 1:size(x_train,2)\n",
    "    if softmax(model(x_train[:,i]))[1]>0.5\n",
    "        push!(simplified_x_train_result, 0)\n",
    "    else\n",
    "        push!(simplified_x_train_result, 1)\n",
    "    end\n",
    "end\n",
    "simplified_y_train = []\n",
    "for i  = 1:size(x_train,2)\n",
    "    if y_train[i] == 0\n",
    "        push!(simplified_y_train, 0)\n",
    "    else\n",
    "        push!(simplified_y_train, 1)\n",
    "    end\n",
    "end\n",
    "\n",
    "# ConfusionMatrix for the training data\n",
    "print(\"ConfusionMatrix for the training data\\n\")\n",
    "ConfusionMatrix()(simplified_x_train_result, simplified_y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConfusionMatrix for the test data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Warning: The classes are un-ordered,\n",
      "│ using: negative='0' and positive='1'.\n",
      "│ To suppress this warning, consider coercing to OrderedFactor.\n",
      "└ @ MLJBase C:\\Users\\xkzmx\\.julia\\packages\\MLJBase\\pCiRR\\src\\measures\\confusion_matrix.jl:112\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "              ┌───────────────────────────┐\n",
       "              │       Ground Truth        │\n",
       "┌─────────────┼─────────────┬─────────────┤\n",
       "│  Predicted  │      0      │      1      │\n",
       "├─────────────┼─────────────┼─────────────┤\n",
       "│      0      │     224     │     104     │\n",
       "├─────────────┼─────────────┼─────────────┤\n",
       "│      1      │     82      │     186     │\n",
       "└─────────────┴─────────────┴─────────────┘\n"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simplified_x_test_result = []\n",
    "for i  = 1:size(x_test,2) \n",
    "    if softmax(model(x_test[:,i]))[1]>0.5\n",
    "        push!(simplified_x_test_result, 0)\n",
    "    else\n",
    "        push!(simplified_x_test_result, 1)\n",
    "    end\n",
    "end\n",
    "simplified_y_test = []\n",
    "for i  = 1:size(x_test,2) \n",
    "    if y_test[i] == 0\n",
    "        push!(simplified_y_test, 0)\n",
    "    else\n",
    "        push!(simplified_y_test, 1)\n",
    "    end\n",
    "end\n",
    "\n",
    "# ConfusionMatrix for the test data\n",
    "print(\"ConfusionMatrix for the test data\\n\")\n",
    "ConfusionMatrix()(simplified_x_test_result, simplified_y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.7.1",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
