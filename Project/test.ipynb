{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Flux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dense(10, 5, σ)     \u001b[90m# 55 parameters\u001b[39m"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = Dense(10, 5, σ)\n",
    "Dense(10, 5, σ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv((2, 2), 3 => 16, relu)  \u001b[90m# 208 parameters\u001b[39m"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1 = Conv((2,2), 3=>16, relu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Params([[-0.10504298 0.015404796; -0.16867483 -0.093925655;;; -0.22369452 0.24144866; -0.25695363 0.028953863;;; -0.21480635 0.2793966; -0.22007127 -0.12986118;;;; 0.1402178 0.06470534; 0.22963177 -0.23883863;;; 0.13937882 -0.16892399; -0.10950718 -0.14344822;;; 0.22863486 -0.15188977; 0.037822396 -0.27065685;;;; -0.032291144 0.09345331; 0.003036467 -0.21945496;;; -0.0362017 0.19099686; -0.018574806 -0.2360038;;; 0.26668087 0.14853734; 0.11189967 0.029282708;;;; … ;;;; 0.16986202 -0.093666546; -0.120102964 -0.20982556;;; 0.2345333 -0.08345895; 0.15178667 -0.24476881;;; -0.025395593 0.015627962; -0.07704722 0.15003562;;;; 0.20504421 -0.20896418; 0.07469503 -0.17985314;;; 0.17644447 0.10599588; 0.14106362 0.04498289;;; 0.14253268 -0.115359634; 0.2202937 -0.008101503;;;; -0.088218585 0.0598401; 0.21259719 -0.16799112;;; -0.20538619 -0.2549271; -0.0051128482 -0.03213933;;; -0.067858554 -0.012613355; -0.11846346 -0.11896477], Float32[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params(m1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "type Conv has no field destruct",
     "output_type": "error",
     "traceback": [
      "type Conv has no field destruct",
      "",
      "Stacktrace:",
      " [1] getproperty(x::Conv{2, 4, typeof(relu), Array{Float32, 4}, Vector{Float32}}, f::Symbol)",
      "   @ Base .\\Base.jl:42",
      " [2] top-level scope",
      "   @ In[6]:1",
      " [3] eval",
      "   @ .\\boot.jl:373 [inlined]",
      " [4] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "   @ Base .\\loading.jl:1196"
     ]
    }
   ],
   "source": [
    "m1.destruct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.10504298 0.015404796; -0.16867483 -0.093925655;;; -0.22369452 0.24144866; -0.25695363 0.028953863;;; -0.21480635 0.2793966; -0.22007127 -0.12986118;;;; 0.1402178 0.06470534; 0.22963177 -0.23883863;;; 0.13937882 -0.16892399; -0.10950718 -0.14344822;;; 0.22863486 -0.15188977; 0.037822396 -0.27065685;;;; -0.032291144 0.09345331; 0.003036467 -0.21945496;;; -0.0362017 0.19099686; -0.018574806 -0.2360038;;; 0.26668087 0.14853734; 0.11189967 0.029282708;;;; 0.22698182 -0.2594458; -0.24087381 -0.27783492;;; 0.0053367172 0.092637494; 0.20550688 0.09135356;;; -0.20218468 0.22365063; -0.03539913 0.14030981;;;; -0.19232641 -0.2517304; 0.1273636 0.26090866;;; 0.2310349 0.07648411; -0.08145781 -0.09208273;;; 0.12249914 -0.25479174; 0.10015896 -0.122776285;;;; 0.044538002 -0.12192282; -0.13241926 0.03477641;;; -0.20481317 -0.068774655; 0.05676266 0.020949826;;; -0.2763204 -0.20864905; -0.14659135 -0.06415796;;;; 0.2066809 -0.25882295; -0.15271008 -0.14038168;;; 0.16244982 0.22742148; 0.09098472 -0.13368304;;; 0.025408637 0.0194101; -0.16124535 -0.25777835;;;; 0.2714203 -0.27233884; -0.011394598 -0.116311066;;; -0.021963524 0.019371811; 0.01903113 -0.13800137;;; -0.24259138 -0.21837008; 0.10697096 0.16947356;;;; 0.027392242 -0.018753648; -0.25635993 -0.0023399813;;; -0.2054254 -0.2167925; 0.10409157 0.096144095;;; 0.26229075 -0.067001976; 0.24149902 -0.011255857;;;; -0.02768716 -0.08887983; 0.23951383 -0.24797772;;; 0.27250326 -0.15610564; 0.022113027 0.24132718;;; -0.05171496 0.20735958; -0.0028019694 -0.2124683;;;; -0.0072941394 0.076034054; -0.03329348 0.24947569;;; -0.22715037 -0.24732424; -0.27511567 -0.034382213;;; -0.19502297 0.06438183; -0.175419 -0.10128122;;;; -0.08587737 -0.2528285; -0.08197408 -0.24694984;;; 0.24453096 0.00055160944; -0.21076275 -0.1553367;;; -0.115393996 0.045625396; -0.25635928 0.033244796;;;; -0.072849795 0.15968648; 0.16940026 -0.2588832;;; -0.043980893 -0.076577924; -0.16616309 -0.13208072;;; -0.18905562 -0.26489225; 0.23880193 0.086772874;;;; 0.16986202 -0.093666546; -0.120102964 -0.20982556;;; 0.2345333 -0.08345895; 0.15178667 -0.24476881;;; -0.025395593 0.015627962; -0.07704722 0.15003562;;;; 0.20504421 -0.20896418; 0.07469503 -0.17985314;;; 0.17644447 0.10599588; 0.14106362 0.04498289;;; 0.14253268 -0.115359634; 0.2202937 -0.008101503;;;; -0.088218585 0.0598401; 0.21259719 -0.16799112;;; -0.20538619 -0.2549271; -0.0051128482 -0.03213933;;; -0.067858554 -0.012613355; -0.11846346 -0.11896477]Float32[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
     ]
    }
   ],
   "source": [
    "for p in params(m1)\n",
    "    print(p)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Params([[-0.10504298 0.015404796; -0.16867483 -0.093925655;;; -0.22369452 0.24144866; -0.25695363 0.028953863;;; -0.21480635 0.2793966; -0.22007127 -0.12986118;;;; 0.1402178 0.06470534; 0.22963177 -0.23883863;;; 0.13937882 -0.16892399; -0.10950718 -0.14344822;;; 0.22863486 -0.15188977; 0.037822396 -0.27065685;;;; -0.032291144 0.09345331; 0.003036467 -0.21945496;;; -0.0362017 0.19099686; -0.018574806 -0.2360038;;; 0.26668087 0.14853734; 0.11189967 0.029282708;;;; … ;;;; 0.16986202 -0.093666546; -0.120102964 -0.20982556;;; 0.2345333 -0.08345895; 0.15178667 -0.24476881;;; -0.025395593 0.015627962; -0.07704722 0.15003562;;;; 0.20504421 -0.20896418; 0.07469503 -0.17985314;;; 0.17644447 0.10599588; 0.14106362 0.04498289;;; 0.14253268 -0.115359634; 0.2202937 -0.008101503;;;; -0.088218585 0.0598401; 0.21259719 -0.16799112;;; -0.20538619 -0.2549271; -0.0051128482 -0.03213933;;; -0.067858554 -0.012613355; -0.11846346 -0.11896477], Float32[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params(m1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "\\begin{verbatim}\n",
       "Conv(filter, in => out, σ = identity;\n",
       "     stride = 1, pad = 0, dilation = 1, groups = 1, [bias, weight, init])\n",
       "\\end{verbatim}\n",
       "Standard convolutional layer. \\texttt{filter} is a tuple of integers specifying the size of the convolutional kernel; \\texttt{in} and \\texttt{out} specify the number of input and output channels.\n",
       "\n",
       "Image data should be stored in WHCN order (width, height, channels, batch). In other words, a 100×100 RGB image would be a \\texttt{100×100×3×1} array, and a batch of 50 would be a \\texttt{100×100×3×50} array. This has \\texttt{N = 2} spatial dimensions, and needs a kernel size like \\texttt{(5,5)}, a 2-tuple of integers.\n",
       "\n",
       "To take convolutions along \\texttt{N} feature dimensions, this layer expects as input an array with \\texttt{ndims(x) == N+2}, where \\texttt{size(x, N+1) == in} is the number of input channels, and \\texttt{size(x, ndims(x))} is (as always) the number of observations in a batch. Then:\n",
       "\n",
       "\\begin{itemize}\n",
       "\\item \\texttt{filter} should be a tuple of \\texttt{N} integers.\n",
       "\n",
       "\n",
       "\\item Keywords \\texttt{stride} and \\texttt{dilation} should each be either single integer, or a tuple with \\texttt{N} integers.\n",
       "\n",
       "\n",
       "\\item Keyword \\texttt{pad} specifies the number of elements added to the borders of the data array. It can be\n",
       "\n",
       "\\begin{itemize}\n",
       "\\item a single integer for equal padding all around,\n",
       "\n",
       "\n",
       "\\item a tuple of \\texttt{N} integers, to apply the same padding at begin/end of each spatial dimension,\n",
       "\n",
       "\n",
       "\\item a tuple of \\texttt{2*N} integers, for asymmetric padding, or\n",
       "\n",
       "\n",
       "\\item the singleton \\texttt{SamePad()}, to calculate padding such that \\texttt{size(output,d) == size(x,d) / stride} (possibly rounded) for each spatial dimension.\n",
       "\n",
       "\\end{itemize}\n",
       "\n",
       "\\item Keyword \\texttt{groups} is expected to be an \\texttt{Int}. It specifies the number of groups to divide a convolution into.\n",
       "\n",
       "\\end{itemize}\n",
       "Keywords to control initialization of the layer:\n",
       "\n",
       "\\begin{itemize}\n",
       "\\item \\texttt{init} - Function used to generate initial weights. Defaults to \\texttt{glorot\\_uniform}.\n",
       "\n",
       "\n",
       "\\item \\texttt{weight} - Initial weights of the layer. Typically an array, and can be used to override other configurations. By default, these are generated using \\href{@ref}{\\texttt{convfilter}}.\n",
       "\n",
       "\n",
       "\\item \\texttt{bias} - Initial bias is zero by default, this can be disabled entirely by setting it to \\href{@ref}{\\texttt{Flux.Zeros()}} or equivalently \\texttt{false}, or another vector provided as \\texttt{bias = randn(Float32, out)}.\n",
       "\n",
       "\\end{itemize}\n",
       "See also \\href{@ref}{\\texttt{ConvTranspose}}, \\href{@ref}{\\texttt{DepthwiseConv}}, \\href{@ref}{\\texttt{CrossCor}}.\n",
       "\n",
       "\\section{Examples}\n",
       "\\begin{verbatim}\n",
       "julia> xs = rand(Float32, 100, 100, 3, 50); # a batch of images\n",
       "\n",
       "julia> layer = Conv((5,5), 3 => 7, relu; bias = false)\n",
       "Conv((5, 5), 3 => 7, relu, bias=false)  # 525 parameters\n",
       "\n",
       "julia> layer(xs) |> size\n",
       "(96, 96, 7, 50)\n",
       "\n",
       "julia> Conv((5,5), 3 => 7; stride = 2)(xs) |> size\n",
       "(48, 48, 7, 50)\n",
       "\n",
       "julia> Conv((5,5), 3 => 7; stride = 2, pad = SamePad())(xs) |> size\n",
       "(50, 50, 7, 50)\n",
       "\n",
       "julia> Conv((1,1), 3 => 7; pad = (20,10,0,0))(xs) |> size\n",
       "(130, 100, 7, 50)\n",
       "\n",
       "julia> Conv((5,5), 3 => 7; stride = 2, dilation = 4)(xs) |> size\n",
       "(42, 42, 7, 50)\n",
       "\\end{verbatim}\n",
       "\\rule{\\textwidth}{1pt}\n",
       "\\begin{verbatim}\n",
       "Conv(weight::AbstractArray, [bias, activation; stride, pad, dilation])\n",
       "\\end{verbatim}\n",
       "Constructs a convolutional layer with the given weight and bias. Accepts the same keywords (and has the same defaults) as the \\texttt{Conv((4,4), 3 => 7, relu)} method.\n",
       "\n",
       "\\section{Examples}\n",
       "\\begin{verbatim}\n",
       "julia> weight = rand(3, 4, 5);\n",
       "\n",
       "julia> bias = zeros(5);\n",
       "\n",
       "julia> c1 = Conv(weight, bias, sigmoid)  # expects 1 spatial dimension\n",
       "Conv((3,), 4 => 5, σ)  # 65 parameters\n",
       "\n",
       "julia> c1(randn(100, 4, 64)) |> size\n",
       "(98, 5, 64)\n",
       "\n",
       "julia> params(c1) |> length\n",
       "2\n",
       "\\end{verbatim}\n"
      ],
      "text/markdown": [
       "```\n",
       "Conv(filter, in => out, σ = identity;\n",
       "     stride = 1, pad = 0, dilation = 1, groups = 1, [bias, weight, init])\n",
       "```\n",
       "\n",
       "Standard convolutional layer. `filter` is a tuple of integers specifying the size of the convolutional kernel; `in` and `out` specify the number of input and output channels.\n",
       "\n",
       "Image data should be stored in WHCN order (width, height, channels, batch). In other words, a 100×100 RGB image would be a `100×100×3×1` array, and a batch of 50 would be a `100×100×3×50` array. This has `N = 2` spatial dimensions, and needs a kernel size like `(5,5)`, a 2-tuple of integers.\n",
       "\n",
       "To take convolutions along `N` feature dimensions, this layer expects as input an array with `ndims(x) == N+2`, where `size(x, N+1) == in` is the number of input channels, and `size(x, ndims(x))` is (as always) the number of observations in a batch. Then:\n",
       "\n",
       "  * `filter` should be a tuple of `N` integers.\n",
       "  * Keywords `stride` and `dilation` should each be either single integer, or a tuple with `N` integers.\n",
       "  * Keyword `pad` specifies the number of elements added to the borders of the data array. It can be\n",
       "\n",
       "      * a single integer for equal padding all around,\n",
       "      * a tuple of `N` integers, to apply the same padding at begin/end of each spatial dimension,\n",
       "      * a tuple of `2*N` integers, for asymmetric padding, or\n",
       "      * the singleton `SamePad()`, to calculate padding such that `size(output,d) == size(x,d) / stride` (possibly rounded) for each spatial dimension.\n",
       "  * Keyword `groups` is expected to be an `Int`. It specifies the number of groups to divide a convolution into.\n",
       "\n",
       "Keywords to control initialization of the layer:\n",
       "\n",
       "  * `init` - Function used to generate initial weights. Defaults to `glorot_uniform`.\n",
       "  * `weight` - Initial weights of the layer. Typically an array, and can be used to override other configurations. By default, these are generated using [`convfilter`](@ref).\n",
       "  * `bias` - Initial bias is zero by default, this can be disabled entirely by setting it to [`Flux.Zeros()`](@ref) or equivalently `false`, or another vector provided as `bias = randn(Float32, out)`.\n",
       "\n",
       "See also [`ConvTranspose`](@ref), [`DepthwiseConv`](@ref), [`CrossCor`](@ref).\n",
       "\n",
       "# Examples\n",
       "\n",
       "```jldoctest\n",
       "julia> xs = rand(Float32, 100, 100, 3, 50); # a batch of images\n",
       "\n",
       "julia> layer = Conv((5,5), 3 => 7, relu; bias = false)\n",
       "Conv((5, 5), 3 => 7, relu, bias=false)  # 525 parameters\n",
       "\n",
       "julia> layer(xs) |> size\n",
       "(96, 96, 7, 50)\n",
       "\n",
       "julia> Conv((5,5), 3 => 7; stride = 2)(xs) |> size\n",
       "(48, 48, 7, 50)\n",
       "\n",
       "julia> Conv((5,5), 3 => 7; stride = 2, pad = SamePad())(xs) |> size\n",
       "(50, 50, 7, 50)\n",
       "\n",
       "julia> Conv((1,1), 3 => 7; pad = (20,10,0,0))(xs) |> size\n",
       "(130, 100, 7, 50)\n",
       "\n",
       "julia> Conv((5,5), 3 => 7; stride = 2, dilation = 4)(xs) |> size\n",
       "(42, 42, 7, 50)\n",
       "```\n",
       "\n",
       "---\n",
       "\n",
       "```\n",
       "Conv(weight::AbstractArray, [bias, activation; stride, pad, dilation])\n",
       "```\n",
       "\n",
       "Constructs a convolutional layer with the given weight and bias. Accepts the same keywords (and has the same defaults) as the `Conv((4,4), 3 => 7, relu)` method.\n",
       "\n",
       "# Examples\n",
       "\n",
       "```jldoctest\n",
       "julia> weight = rand(3, 4, 5);\n",
       "\n",
       "julia> bias = zeros(5);\n",
       "\n",
       "julia> c1 = Conv(weight, bias, sigmoid)  # expects 1 spatial dimension\n",
       "Conv((3,), 4 => 5, σ)  # 65 parameters\n",
       "\n",
       "julia> c1(randn(100, 4, 64)) |> size\n",
       "(98, 5, 64)\n",
       "\n",
       "julia> params(c1) |> length\n",
       "2\n",
       "```\n"
      ],
      "text/plain": [
       "\u001b[36m  Conv(filter, in => out, σ = identity;\u001b[39m\n",
       "\u001b[36m       stride = 1, pad = 0, dilation = 1, groups = 1, [bias, weight, init])\u001b[39m\n",
       "\n",
       "  Standard convolutional layer. \u001b[36mfilter\u001b[39m is a tuple of integers specifying the\n",
       "  size of the convolutional kernel; \u001b[36min\u001b[39m and \u001b[36mout\u001b[39m specify the number of input and\n",
       "  output channels.\n",
       "\n",
       "  Image data should be stored in WHCN order (width, height, channels, batch).\n",
       "  In other words, a 100×100 RGB image would be a \u001b[36m100×100×3×1\u001b[39m array, and a\n",
       "  batch of 50 would be a \u001b[36m100×100×3×50\u001b[39m array. This has \u001b[36mN = 2\u001b[39m spatial\n",
       "  dimensions, and needs a kernel size like \u001b[36m(5,5)\u001b[39m, a 2-tuple of integers.\n",
       "\n",
       "  To take convolutions along \u001b[36mN\u001b[39m feature dimensions, this layer expects as input\n",
       "  an array with \u001b[36mndims(x) == N+2\u001b[39m, where \u001b[36msize(x, N+1) == in\u001b[39m is the number of\n",
       "  input channels, and \u001b[36msize(x, ndims(x))\u001b[39m is (as always) the number of\n",
       "  observations in a batch. Then:\n",
       "\n",
       "    •  \u001b[36mfilter\u001b[39m should be a tuple of \u001b[36mN\u001b[39m integers.\n",
       "\n",
       "    •  Keywords \u001b[36mstride\u001b[39m and \u001b[36mdilation\u001b[39m should each be either single integer,\n",
       "       or a tuple with \u001b[36mN\u001b[39m integers.\n",
       "\n",
       "    •  Keyword \u001b[36mpad\u001b[39m specifies the number of elements added to the borders\n",
       "       of the data array. It can be\n",
       "       • a single integer for equal padding all around,\n",
       "       • a tuple of \u001b[36mN\u001b[39m integers, to apply the same padding at\n",
       "       begin/end of each spatial dimension,\n",
       "       • a tuple of \u001b[36m2*N\u001b[39m integers, for asymmetric padding, or\n",
       "       • the singleton \u001b[36mSamePad()\u001b[39m, to calculate padding such that\n",
       "       \u001b[36msize(output,d) == size(x,d) / stride\u001b[39m (possibly rounded)\n",
       "       for each spatial dimension.\n",
       "\n",
       "    •  Keyword \u001b[36mgroups\u001b[39m is expected to be an \u001b[36mInt\u001b[39m. It specifies the number\n",
       "       of groups to divide a convolution into.\n",
       "\n",
       "  Keywords to control initialization of the layer:\n",
       "\n",
       "    •  \u001b[36minit\u001b[39m - Function used to generate initial weights. Defaults to\n",
       "       \u001b[36mglorot_uniform\u001b[39m.\n",
       "\n",
       "    •  \u001b[36mweight\u001b[39m - Initial weights of the layer. Typically an array, and can\n",
       "       be used to override other configurations. By default, these are\n",
       "       generated using \u001b[36mconvfilter\u001b[39m.\n",
       "\n",
       "    •  \u001b[36mbias\u001b[39m - Initial bias is zero by default, this can be disabled\n",
       "       entirely by setting it to \u001b[36mFlux.Zeros()\u001b[39m or equivalently \u001b[36mfalse\u001b[39m, or\n",
       "       another vector provided as \u001b[36mbias = randn(Float32, out)\u001b[39m.\n",
       "\n",
       "  See also \u001b[36mConvTranspose\u001b[39m, \u001b[36mDepthwiseConv\u001b[39m, \u001b[36mCrossCor\u001b[39m.\n",
       "\n",
       "\u001b[1m  Examples\u001b[22m\n",
       "\u001b[1m  ≡≡≡≡≡≡≡≡≡≡\u001b[22m\n",
       "\n",
       "\u001b[36m  julia> xs = rand(Float32, 100, 100, 3, 50); # a batch of images\u001b[39m\n",
       "\u001b[36m  \u001b[39m\n",
       "\u001b[36m  julia> layer = Conv((5,5), 3 => 7, relu; bias = false)\u001b[39m\n",
       "\u001b[36m  Conv((5, 5), 3 => 7, relu, bias=false)  # 525 parameters\u001b[39m\n",
       "\u001b[36m  \u001b[39m\n",
       "\u001b[36m  julia> layer(xs) |> size\u001b[39m\n",
       "\u001b[36m  (96, 96, 7, 50)\u001b[39m\n",
       "\u001b[36m  \u001b[39m\n",
       "\u001b[36m  julia> Conv((5,5), 3 => 7; stride = 2)(xs) |> size\u001b[39m\n",
       "\u001b[36m  (48, 48, 7, 50)\u001b[39m\n",
       "\u001b[36m  \u001b[39m\n",
       "\u001b[36m  julia> Conv((5,5), 3 => 7; stride = 2, pad = SamePad())(xs) |> size\u001b[39m\n",
       "\u001b[36m  (50, 50, 7, 50)\u001b[39m\n",
       "\u001b[36m  \u001b[39m\n",
       "\u001b[36m  julia> Conv((1,1), 3 => 7; pad = (20,10,0,0))(xs) |> size\u001b[39m\n",
       "\u001b[36m  (130, 100, 7, 50)\u001b[39m\n",
       "\u001b[36m  \u001b[39m\n",
       "\u001b[36m  julia> Conv((5,5), 3 => 7; stride = 2, dilation = 4)(xs) |> size\u001b[39m\n",
       "\u001b[36m  (42, 42, 7, 50)\u001b[39m\n",
       "\n",
       "  ────────────────────────────────────────────────────────────────────────────\n",
       "\n",
       "\u001b[36m  Conv(weight::AbstractArray, [bias, activation; stride, pad, dilation])\u001b[39m\n",
       "\n",
       "  Constructs a convolutional layer with the given weight and bias. Accepts the\n",
       "  same keywords (and has the same defaults) as the \u001b[36mConv((4,4), 3 => 7, relu)\u001b[39m\n",
       "  method.\n",
       "\n",
       "\u001b[1m  Examples\u001b[22m\n",
       "\u001b[1m  ≡≡≡≡≡≡≡≡≡≡\u001b[22m\n",
       "\n",
       "\u001b[36m  julia> weight = rand(3, 4, 5);\u001b[39m\n",
       "\u001b[36m  \u001b[39m\n",
       "\u001b[36m  julia> bias = zeros(5);\u001b[39m\n",
       "\u001b[36m  \u001b[39m\n",
       "\u001b[36m  julia> c1 = Conv(weight, bias, sigmoid)  # expects 1 spatial dimension\u001b[39m\n",
       "\u001b[36m  Conv((3,), 4 => 5, σ)  # 65 parameters\u001b[39m\n",
       "\u001b[36m  \u001b[39m\n",
       "\u001b[36m  julia> c1(randn(100, 4, 64)) |> size\u001b[39m\n",
       "\u001b[36m  (98, 5, 64)\u001b[39m\n",
       "\u001b[36m  \u001b[39m\n",
       "\u001b[36m  julia> params(c1) |> length\u001b[39m\n",
       "\u001b[36m  2\u001b[39m"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "? Flux.Conv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3×4×5 Array{Float64, 3}:\n",
       "[:, :, 1] =\n",
       " 0.903708  0.151379   0.343022  0.619285\n",
       " 0.609166  0.0133665  0.161565  0.81916\n",
       " 0.717769  0.582652   0.414007  0.987545\n",
       "\n",
       "[:, :, 2] =\n",
       " 0.452888  0.817191  0.0284931  0.927105\n",
       " 0.862647  0.804041  0.685436   0.132652\n",
       " 0.966385  0.79301   0.29135    0.352622\n",
       "\n",
       "[:, :, 3] =\n",
       " 0.267211  0.307972  0.943526   0.530126\n",
       " 0.268772  0.136896  0.866589   0.725978\n",
       " 0.987899  0.650302  0.0319665  0.48523\n",
       "\n",
       "[:, :, 4] =\n",
       " 0.227273   0.992605  0.00996568  0.701058\n",
       " 0.0783944  0.48895   0.586653    0.734873\n",
       " 0.588727   0.243842  0.973113    0.915352\n",
       "\n",
       "[:, :, 5] =\n",
       " 0.097986  0.678739   0.655092   0.447673\n",
       " 0.423851  0.538333   0.0505465  0.675562\n",
       " 0.517877  0.0445776  0.188689   0.154117"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight = rand(3, 4, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5-element Vector{Float64}:\n",
       " 1.0\n",
       " 1.0\n",
       " 1.0\n",
       " 1.0\n",
       " 1.0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bias = ones(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Params([[0.9037081536209858 0.1513785578417154 0.34302230139531265 0.6192848384284907; 0.6091664755510678 0.013366468364803485 0.16156478098281668 0.8191600337643465; 0.7177690698319428 0.5826522513463293 0.4140072875648043 0.9875447157884624;;; 0.4528876473115093 0.8171911347815645 0.02849306917684824 0.9271047418504061; 0.8626465122624888 0.8040411107256467 0.6854360471991298 0.13265241631797464; 0.9663852048609914 0.7930104445094391 0.291349687196402 0.35262241524002547;;; 0.267211220073194 0.30797202917893074 0.9435257960962554 0.5301257651194088; 0.26877197889100624 0.1368961951989469 0.8665886094231855 0.7259780677894481; 0.9878991670135258 0.650301825960088 0.03196646994029906 0.4852298687211696;;; 0.22727303245214292 0.9926053988640258 0.009965683816268944 0.7010579067275077; 0.07839441745580056 0.4889496707190615 0.586652522618943 0.7348729042033064; 0.5887272303587815 0.24384176836697735 0.9731125881364776 0.9153516886896977;;; 0.09798597847473112 0.678738753466052 0.6550916244593232 0.447672526224673; 0.42385081677969194 0.5383331454444024 0.05054652370511281 0.6755618474711313; 0.517877218714848 0.04457759228629521 0.18868885976472005 0.154117103421747], [1.0, 1.0, 1.0, 1.0, 1.0]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c1 = Conv(weight, bias, sigmoid)  # expects 1 spatial dimension\n",
    "  Conv((3,), 4=>5, σ)\n",
    "params(c1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.7.1",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
