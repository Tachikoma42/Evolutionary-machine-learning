{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Evolutionary\n",
    "using Flux\n",
    "using Flux: onehot, onecold, logitcrossentropy, onehotbatch, crossentropy \n",
    "using MLDatasets\n",
    "using Random\n",
    "using Statistics\n",
    "using MLJBase\n",
    "using Printf\n",
    "using BSON: @load # for load weights\n",
    "using Plots\n",
    "using DelimitedFiles\n",
    "import Evolutionary.initial_population\n",
    "import Evolutionary.EvolutionaryObjective\n",
    "using Zygote\n",
    "import Base: copy\n",
    "using StableRNGs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "random seed for Evolutionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TaskLocalRNG()"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Random.seed!(63456345)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in and balance data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawdata = readdlm(\"data/test2.csv\",',',skipstart=1)';\n",
    "one = 0\n",
    "zero = 0\n",
    "for i in rawdata[20,:]\n",
    "    if i == 1\n",
    "        one = one + 1\n",
    "    else\n",
    "        zero = zero + 1\n",
    "    end\n",
    "end\n",
    "\n",
    "difference = one - zero\n",
    "\n",
    "function newrand()\n",
    "    randCol = zeros(0)\n",
    "    push!(randCol, rand(10.0:99.0))\n",
    "    push!(randCol, rand(5.3:40.2))\n",
    "    push!(randCol, rand(1.1:15.1))\n",
    "    push!(randCol, rand(0.1:8.1))\n",
    "    push!(randCol, rand(1.1:15.1))\n",
    "    push!(randCol, rand(30.1:60.1))\n",
    "    push!(randCol, rand(0.1:0.9))\n",
    "    push!(randCol, rand(0.1:4.1))\n",
    "    push!(randCol, rand(20.1:50.1))\n",
    "    push!(randCol, rand(0.1:5.1))\n",
    "    push!(randCol, rand(0.1:7.1))\n",
    "    push!(randCol, rand(45.1:99.1))\n",
    "    push!(randCol, rand(0.1:5.1))\n",
    "    push!(randCol, rand(0.1:5.1))\n",
    "    push!(randCol, rand(0.1:7.1))\n",
    "    push!(randCol, rand(0.1:7.1))\n",
    "    push!(randCol, rand(0.1:3.1))\n",
    "    push!(randCol, rand(0.1:3.1))\n",
    "    push!(randCol, rand(0.1:5.1))\n",
    "    if rand(0:1) == 0\n",
    "        push!(randCol, 0.0)\n",
    "    else\n",
    "        push!(randCol, 1.0)\n",
    "    end\n",
    "    return randCol\n",
    "end\n",
    "\n",
    "for i = 1:size(rawdata,2)\n",
    "    if rawdata[20,i] == 0 && difference > 0\n",
    "        rawdata = hcat(rawdata, rawdata[:,i])\n",
    "        rawdata = hcat(rawdata, newrand())\n",
    "\n",
    "        difference = difference - 1\n",
    "    end\n",
    "end\n",
    "filldata = rawdata[ :, shuffle(1:end)];\n",
    "\n",
    "x = filldata[1:19, :]\n",
    "y = filldata[20, :];\n",
    "\n",
    "x_train = x[:,1:floor(Int, size(x,2)*0.7)]\n",
    "y_train = y[1:floor(Int, size(x,2)*0.7)]\n",
    "x_test = x[:,floor(Int, size(x,2)*0.7)+1:end]\n",
    "y_test = y[floor(Int, size(x,2)*0.7)+1:end];\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "zip feature & label together using zip instead of batch for Evolutionary function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = [ (x, onehot(l, unique(y_train))) for (x, l) in zip(eachcol(x_train), y_train)]\n",
    "test_data = [ (x, onehot(l, unique(y_test))) for (x, l) in zip(eachcol(x_test), y_test)];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "loss (generic function with 3 methods)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(model,x,y) = mean(onecold(model(x)) .== onecold(y))\n",
    "accuracy(xy, model) = mean( onecold(model(x)) .== onecold(y) for (x,y) in xy)\n",
    "\n",
    "loss(model) = (x,y)->logitcrossentropy(model(x), y)\n",
    "loss(model,x,y) = loss(model)(x, y)\n",
    "loss(xy, model) = loss(model)(hcat(map(first,xy)...), hcat(map(last,xy)...))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the fitness function of evolutionary function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fitness (generic function with 1 method)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fitness(m) = loss(train_data, m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "flat the weight and bias for evolutionary function to evolutionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gaussian_mlp (generic function with 2 methods)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function uniform_mlp(m1::T, m2::T; rng::Random.AbstractRNG=Random.default_rng()) where {T <: Chain}\n",
    "    θ1, re1 = Flux.destructure(m1);\n",
    "    θ2, re2 = Flux.destructure(m2);\n",
    "    c1, c2 = UX(θ1,θ2; rng=rng)\n",
    "    return re1(c1), re2(c2)\n",
    "end\n",
    "\n",
    "function gaussian_mlp(σ::Real = 1.0)\n",
    "    vop = gaussian(σ)\n",
    "    function mutation(recombinant::T; rng::Random.AbstractRNG=Random.default_rng()) where {T <: Chain}  \n",
    "        θ, re = Flux.destructure(recombinant)\n",
    "        return re(convert(Vector{Float32}, vop(θ; rng=rng)))\n",
    "    end\n",
    "    return mutation\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the initial_population function of evolutionary function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "initial_population (generic function with 8 methods)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function initial_population(method::M, individual::Chain;\n",
    "    rng::Random.AbstractRNG=Random.default_rng(),\n",
    "    kwargs...) where {M<:Evolutionary.AbstractOptimizer}\n",
    "θ, re = Flux.destructure(individual);\n",
    "[re(randn(rng, length(θ))) for i in 1:Evolutionary.population_size(method)]\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overload some function for evolutionary function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "copy (generic function with 176 methods)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function EvolutionaryObjective(f, x::Chain; eval::Symbol = :serial)\n",
    "    fval = f(x)\n",
    "    EvolutionaryObjective{typeof(f),typeof(fval),typeof(x),Val{eval}}(f, fval, deepcopy(x), 0)\n",
    "end\n",
    "\n",
    "copy(ch::Chain) = deepcopy(ch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GA[P=1600,x=0.9,μ=0.2,ɛ=0.0003]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the iterations is performed later\n",
    "opts = Evolutionary.Options(iterations=100, successive_f_tol=25, rng=StableRNG(42))\n",
    "algo = GA(\n",
    "        selection = rouletteinv,\n",
    "        mutation =  gaussian_mlp(),\n",
    "        crossover = uniform_mlp,\n",
    "        mutationRate = 0.2,\n",
    "        crossoverRate = 0.9,\n",
    "        populationSize = 1600,\n",
    "        ε = 0.0003\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "samilar code as backpropagation but change the training part using evolutionary.ji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# epochs = 2000 # the number of epochs\n",
    "# # change population_size will increase training time, but may increase the accuracy\n",
    "# save_resultTest = zeros(epochs);\n",
    "# save_resultTrain = zeros(epochs);\n",
    "\n",
    "# model = Chain(Dense(19, 2*19, sigmoid), Dense(2*19, 2))\n",
    "# # load the models saved from HW1, the softmax is removed because it does not need to train\n",
    "\n",
    "# for i in 1:10\n",
    "#     # change the model\n",
    "#     # load the models saved from HW1\n",
    "#     loadpath = string(\"models/model\",i,\".bson\")\n",
    "#     @load loadpath weights\n",
    "#     Flux.loadparams!(model, weights)\n",
    "#     # the models are started with the same hyperparameters\n",
    "#     res = Evolutionary.optimize(fitness, model, algo, opts)\n",
    "#     evomodel = Evolutionary.minimizer(res)\n",
    "#     # training the model\n",
    "#     for j in 1:epochs\n",
    "#         res = Evolutionary.optimize(fitness, model, algo, opts)\n",
    "#         model= Evolutionary.minimizer(res)\n",
    "#         if j%(epochs/5) == 0\n",
    "#         @printf(\"Loss in expirment %d epoch: %d in test data is %f\\n\",i, j, loss(test_data,model))\n",
    "#         end\n",
    "#         save_resultTest[j] = save_resultTest[j] + accuracy(test_data, model)\n",
    "#         save_resultTrain[j] = save_resultTrain[j] + accuracy(train_data, model)\n",
    "#     end\n",
    "# end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " * Status: failure (reached maximum number of iterations)\n",
       "\n",
       " * Candidate solution\n",
       "    Minimizer:  Chain(Dense(19, 38, σ), Dense(38, 2))\n",
       "    Minimum:    0.6703265664281358\n",
       "    Iterations: 100\n",
       "\n",
       " * Found with\n",
       "    Algorithm: GA[P=1600,x=0.9,μ=0.2,ɛ=0.0003]\n",
       "\n",
       " * Convergence measures\n",
       "    |f(x) - f(x')| = 0.012819815334979778 ≰ 1.0e-12\n",
       "\n",
       " * Work counters\n",
       "    Seconds run:   397.12 (vs limit Inf)\n",
       "    Iterations:    100\n",
       "    f(x) calls:    161600\n"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model = Chain(Dense(19, 2*19, sigmoid), Dense(2*19, 2))\n",
    "\n",
    "res = Evolutionary.optimize(fitness, model, algo, opts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Chain(\n",
       "  Dense(19, 38, σ),                     \u001b[90m# 760 parameters\u001b[39m\n",
       "  Dense(38, 2),                         \u001b[90m# 78 parameters\u001b[39m\n",
       ")\u001b[90m                   # Total: 4 arrays, \u001b[39m838 parameters, 6.797 KiB."
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model= Evolutionary.minimizer(res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Chain(\n",
       "  Dense(19, 38, σ),                     \u001b[90m# 760 parameters\u001b[39m\n",
       "  Dense(38, 2),                         \u001b[90m# 78 parameters\u001b[39m\n",
       ")\u001b[90m                   # Total: 4 arrays, \u001b[39m838 parameters, 6.797 KiB."
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model = Chain(Dense(19, 2*19, sigmoid), Dense(2*19, 2))\n",
    "res = Evolutionary.optimize(fitness, model, algo, opts)\n",
    "model= Evolutionary.minimizer(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_resultTest = save_resultTest ./ 10;\n",
    "# save_resultTrain = save_resultTrain ./ 10;\n",
    "\n",
    "# plot(log.(1:epochs), save_resultTest,label=\"Test\")\n",
    "# plot!(log.(1:epochs), save_resultTrain,label = \"Train\", title = \"Accuracy\", legend = :outertopleft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: MLP\n",
      "│   loss = 0.6703265664281358\n",
      "│   accuracy = 0.595821325648415\n",
      "└ @ Main In[24]:1\n"
     ]
    }
   ],
   "source": [
    "@info \"MLP\" loss=loss(train_data, model) accuracy = accuracy(train_data, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConfusionMatrix for the training data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Warning: The classes are un-ordered,\n",
      "│ using: negative='0' and positive='1'.\n",
      "│ To suppress this warning, consider coercing to OrderedFactor.\n",
      "└ @ MLJBase C:\\Users\\xkzmx\\.julia\\packages\\MLJBase\\pCiRR\\src\\measures\\confusion_matrix.jl:112\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "              ┌───────────────────────────┐\n",
       "              │       Ground Truth        │\n",
       "┌─────────────┼─────────────┬─────────────┤\n",
       "│  Predicted  │      0      │      1      │\n",
       "├─────────────┼─────────────┼─────────────┤\n",
       "│      0      │     391     │     538     │\n",
       "├─────────────┼─────────────┼─────────────┤\n",
       "│      1      │     298     │     161     │\n",
       "└─────────────┴─────────────┴─────────────┘\n"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simplified_x_train_result = []\n",
    "for i  = 1:size(x_train,2)\n",
    "    if softmax(model(x_train[:,i]))[1]>0.5\n",
    "        push!(simplified_x_train_result, 0)\n",
    "    else\n",
    "        push!(simplified_x_train_result, 1)\n",
    "    end\n",
    "end\n",
    "simplified_y_train = []\n",
    "for i  = 1:size(x_train,2)\n",
    "    if y_train[i] == 0\n",
    "        push!(simplified_y_train, 0)\n",
    "    else\n",
    "        push!(simplified_y_train, 1)\n",
    "    end\n",
    "end\n",
    "\n",
    "# ConfusionMatrix for the training data\n",
    "print(\"ConfusionMatrix for the training data\\n\")\n",
    "ConfusionMatrix()(simplified_x_train_result, simplified_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConfusionMatrix for the test data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Warning: The classes are un-ordered,\n",
      "│ using: negative='0' and positive='1'.\n",
      "│ To suppress this warning, consider coercing to OrderedFactor.\n",
      "└ @ MLJBase C:\\Users\\xkzmx\\.julia\\packages\\MLJBase\\pCiRR\\src\\measures\\confusion_matrix.jl:112\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "              ┌───────────────────────────┐\n",
       "              │       Ground Truth        │\n",
       "┌─────────────┼─────────────┬─────────────┤\n",
       "│  Predicted  │      0      │      1      │\n",
       "├─────────────┼─────────────┼─────────────┤\n",
       "│      0      │     171     │     227     │\n",
       "├─────────────┼─────────────┼─────────────┤\n",
       "│      1      │     135     │     63      │\n",
       "└─────────────┴─────────────┴─────────────┘\n"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simplified_x_test_result = []\n",
    "for i  = 1:size(x_test,2) \n",
    "    if softmax(model(x_test[:,i]))[1]>0.5\n",
    "        push!(simplified_x_test_result, 0)\n",
    "    else\n",
    "        push!(simplified_x_test_result, 1)\n",
    "    end\n",
    "end\n",
    "simplified_y_test = []\n",
    "for i  = 1:size(x_test,2) \n",
    "    if y_test[i] == 0\n",
    "        push!(simplified_y_test, 0)\n",
    "    else\n",
    "        push!(simplified_y_test, 1)\n",
    "    end\n",
    "end\n",
    "\n",
    "# ConfusionMatrix for the test data\n",
    "print(\"ConfusionMatrix for the test data\\n\")\n",
    "ConfusionMatrix()(simplified_x_test_result, simplified_y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.7.1",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
